{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY3h_jD2H3EM"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YJ-uxFxATwR"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xYNbtDzH67E"
      },
      "source": [
        "# Download YOLO weights and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ80l_J0Aekc"
      },
      "outputs": [],
      "source": [
        "# download YOLOv3 weights\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://github.com/pjreddie/darknet/raw/master/cfg/yolov3.cfg\n",
        "!wget https://github.com/pjreddie/darknet/raw/master/data/coco.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XjdNIAzFfl4"
      },
      "outputs": [],
      "source": [
        "# load YOLOv3 network\n",
        "yoloNet = cv.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwupMXdUG-JH"
      },
      "source": [
        "# Define input and output video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJM8q7NtGhQ6"
      },
      "outputs": [],
      "source": [
        "# upload video\n",
        "vid = files.upload().keys()\n",
        "vidPath = list(vid)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2KRFWYoHzq9"
      },
      "outputs": [],
      "source": [
        "# define video capture object\n",
        "cap = cv.VideoCapture(vidPath)\n",
        "\n",
        "# define output video\n",
        "out = cv.VideoWriter('output.mp4', cv.VideoWriter_fourcc(*'MP4V'), 10, (int(cap.get(3)), int(cap.get(4))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWGa_2kmIptV"
      },
      "outputs": [],
      "source": [
        "# load coco classes\n",
        "with open(\"coco.names\", \"r\") as fil:\n",
        "  for line in fil.readlines():\n",
        "    classes = line.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYWovPy9G3nX"
      },
      "source": [
        "# Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lXee7bLIreP"
      },
      "outputs": [],
      "source": [
        "#### function to detect the traffic light and find it's state\n",
        "def detectTrafficLight(img):\n",
        "\n",
        "    # transform image into blob\n",
        "    blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "\n",
        "    # give blob as input to network\n",
        "    yoloNet.setInput(blob)\n",
        "\n",
        "    # get output layer names\n",
        "    outputLayerNames = yoloNet.getUnconnectedOutLayersNames()\n",
        "\n",
        "    # passing output layers names to get outputs at those layers\n",
        "    outputs = yoloNet.forward(outputLayerNames)\n",
        "\n",
        "    confidenceLst = []\n",
        "    classIdsLst = []\n",
        "    boxLst = []\n",
        "\n",
        "    for output in outputs:\n",
        "        for detect in output:\n",
        "\n",
        "            scores = detect[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            conf = scores[classId]\n",
        "\n",
        "            # if the confidence of accuracy is above a certrain threshold and class ID is 9 which represents a traffic light, then detect the object\n",
        "            if conf > 0.5 and classId == 9:\n",
        "                sizeArray = np.array([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
        "                bbox = detect[0:4] * sizeArray\n",
        "                xCenter, yCenter, width, height = bbox.astype(\"int\")\n",
        "\n",
        "                # find the top left coordinates of box\n",
        "                xTopLeft = xCenter - (width / 2)\n",
        "                xTopLeft = int(xTopLeft)\n",
        "                yTopLeft = yCenter - (height / 2)\n",
        "                yTopLeft = int(yTopLeft)\n",
        "\n",
        "                # check if the coordinates are within the range\n",
        "                if xTopLeft < 0:\n",
        "                    xTopLeft = 0\n",
        "                if yTopLeft < 0:\n",
        "                    yTopLeft = 0\n",
        "                if width > img.shape[1]:\n",
        "                    width = img.shape[1]\n",
        "                if height > img.shape[0]:\n",
        "                    height = img.shape[0]\n",
        "\n",
        "                # add detected box values, confidence and class IDs to lists\n",
        "                width = int(width)\n",
        "                height = int(height)\n",
        "                boxLst.append([xTopLeft, yTopLeft, width, height])\n",
        "                confidenceLst.append(float(conf))\n",
        "                classIdsLst.append(classId)\n",
        "    \n",
        "    # apply non-max suppression\n",
        "    nonMaxIdx = cv.dnn.NMSBoxes(boxLst, confidenceLst, 0.5, 0.4)\n",
        "    lenNonMaxIdx = len(nonMaxIdx)\n",
        "\n",
        "    finalDetectLst = []\n",
        "\n",
        "    # use non-max to get remaining detections\n",
        "    for i in range(lenNonMaxIdx):\n",
        "        # currIdx = nonMaxIdx[i]\n",
        "        xTL, yTL, w, h = boxLst[nonMaxIdx[i]]\n",
        "        conf2 = confidenceLst[nonMaxIdx[i]]\n",
        "        classId2 = classIdsLst[nonMaxIdx[i]]\n",
        "\n",
        "        # extract region corresponding to the traffic light\n",
        "        startX = xTL\n",
        "        endX = xTL+w\n",
        "        startY = yTL\n",
        "        endY = yTL+h\n",
        "        trafficLightRegion = img[startY:endY, startX:endX]\n",
        "\n",
        "        # determine state of traffic light\n",
        "        # change to HSV color space\n",
        "        hsv = cv.cvtColor(trafficLightRegion, cv.COLOR_BGR2HSV)\n",
        "\n",
        "        # create masks for red, yellow and green colors using HSV color ranges\n",
        "        red = cv.inRange(hsv, np.array([0, 70, 50]), np.array([10, 255, 255]))\n",
        "        yellow = cv.inRange(hsv, np.array([30, 70, 50]), np.array([40, 255, 255]))\n",
        "        green = cv.inRange(hsv, np.array([50, 70, 50]), np.array([70, 255, 255]))\n",
        "\n",
        "        # count number of pixels in each color\n",
        "        redCount = cv.countNonZero(red)\n",
        "        yellowCount = cv.countNonZero(yellow)\n",
        "        greenCount = cv.countNonZero(green)\n",
        "\n",
        "        # determine state through which pixel count is the highest\n",
        "        if redCount > yellowCount:\n",
        "            state = 'red'\n",
        "        elif redCount > greenCount:\n",
        "            state = 'red'\n",
        "        elif yellowCount > redCount:\n",
        "            state = 'yellow'\n",
        "        elif yellowCount > greenCount:\n",
        "          state = 'yellow'\n",
        "        else:\n",
        "          state = 'green'\n",
        "\n",
        "        finalDetectLst.append((xTL, yTL, w, h, conf2, classId2, state))\n",
        "\n",
        "    return finalDetectLst\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### function to draw bounding boxes and label state of traffic light\n",
        "def labelState(img, detects):\n",
        "    for x1, y1, width, height, conf, classId, state in detects:\n",
        "        # label = f\"{str(state)}:{conf:.2f}\"\n",
        "        label = f\"{str(state)}\"\n",
        "        cv.rectangle(img, (x1, y1), (x1 + width, y1 + height), (0, 255, 0), 2)\n",
        "        cv.putText(img, label, (x1, y1 + height + 40), cv.FONT_HERSHEY_PLAIN, 0.9, (0, 255, 0), 2)\n",
        "    return img"
      ],
      "metadata": {
        "id": "oIrGywCMECph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwezHdvdID82"
      },
      "source": [
        "# Read video and perform detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX0SrUU-JFMV"
      },
      "outputs": [],
      "source": [
        "# read until video is complete\n",
        "while cap.isOpened():\n",
        "    \n",
        "    # read the current frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # if the frame does not exist, break\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # detect state of traffic light\n",
        "    detectVals = detectTrafficLight(frame)\n",
        "\n",
        "    # label state of traffic light\n",
        "    labeledFrame = labelState(frame, detectVals)\n",
        "\n",
        "    # put labeled frame in output video\n",
        "    cv2_imshow(labeledFrame)\n",
        "    out.write(labeledFrame)\n",
        "\n",
        "    # # press q to exit frame\n",
        "    # if cv.waitKey(1) == ord('q'):\n",
        "    #     break\n",
        "\n",
        "# release video capture object  \n",
        "cap.release()\n",
        "\n",
        "# release the output video\n",
        "out.release()\n",
        "\n",
        "# close all the windows\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "print('Completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQa87bk7PiKc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}